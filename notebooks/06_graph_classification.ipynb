{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification with PyTorch Geometric\n",
    "\n",
    "Graph classification is a task where we aim to predict a label for an entire graph, rather than individual nodes or edges.\n",
    "This is a natural extension to node or edge classification and has applications in areas like molecule classification, social network classification, etc.\n",
    "In this notebook, we'll dive into this task using PyTorch Geometric.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Loading the Dataset](#Loading-the-Dataset)\n",
    "2. [Defining the Model](#Defining-the-Model)\n",
    "3. [Setting up the Training Loop](#Setting-up-the-Training-Loop)\n",
    "4. [Evaluating Training Results](#Evaluating-Training-Results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to install the required packages\n",
    "# !pip install torch torchaudio torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset <a name=\"Loading-the-Dataset\"></a>\n",
    "\n",
    "PyTorch Geometric offers datasets that are particularly tailored for graph classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Number of graph features: 3\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# Switching to the PROTEINS dataset\n",
    "dataset = TUDataset(root='/tmp/PROTEINS', name='PROTEINS')\n",
    "\n",
    "# Splitting the dataset\n",
    "train_dataset = dataset[:len(dataset) // 10 * 8]\n",
    "test_dataset = dataset[len(dataset) // 10 * 8:]\n",
    "\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(f'Number of graph features: {dataset.num_features}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model <a name=\"Defining-the-Model\"></a>\n",
    "\n",
    "We'll use a Graph Convolution Network (GCN) followed by global pooling to perform graph classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        return F.log_softmax(self.fc(x), dim=1)\n",
    "\n",
    "# Move model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")  # Use mps to train on mac m1 gpu\n",
    "model = GraphClassifier(input_dim=dataset.num_features, hidden_dim=64, output_dim=dataset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Training Loop <a name=\"Setting-up-the-Training-Loop\"></a>\n",
    "\n",
    "Let's train our graph classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenzhang/micromamba/envs/gnn_tutorial/lib/python3.11/site-packages/torch_geometric/nn/pool/glob.py:62: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  size = int(batch.max().item() + 1) if size is None else size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.45274659991264343\n",
      "Epoch: 10, Loss: 0.47858163714408875\n",
      "Epoch: 20, Loss: 0.49092409014701843\n",
      "Epoch: 30, Loss: 0.5761591792106628\n",
      "Epoch: 40, Loss: 0.49991852045059204\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print loss for every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Training Results <a name=\"Evaluating-Training-Results\"></a>\n",
    "\n",
    "It's time to evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2756\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "        \n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "test_accuracy = compute_accuracy(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuaracy is very low, but this is expected since we're using a very simple model.\n",
    "To improve the performance, we can try out different architectures, hyperparameters, and datasets.\n",
    "And as before, try out Optuna and DeepHyper for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
