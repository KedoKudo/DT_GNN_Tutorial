{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KedoKudo/DT_GNN_Tutorial/blob/tree/main/notebooks/05_node_classification.ipynb)\n",
    "\n",
    "# Node Classification with PyTorch Geometric\n",
    "\n",
    "In this notebook, we'll explore one of the foundational tasks in graph learning: node classification using pyg.\n",
    "Essentially, given a graph with some labeled and some unlabeled nodes, our aim is to predict the labels of the unlabeled nodes.\n",
    "This exercise will not only give us a hands-on understanding of the problem but also showcase the power and utility of PyTorch Geometric in dealing with graph-based learning problems.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. [Loading the Dataset](#Loading-the-Dataset)\n",
    "0. [Defining the Model](#Defining-the-Model)\n",
    "0. [Setting up the Training Loop](#Setting-up-the-Training-Loop)\n",
    "0. [Evaluating Training Results](#Evaluating-Training-Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to install the required packages if needed.\n",
    "# !pip install torch torchvision torchaudio pytorch-gemetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset <a name=\"Loading-the-Dataset\"></a>\n",
    "\n",
    "PyTorch Geometric provides several benchmark datasets tailored for the node classification problem. Let's use one such dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 7\n",
      "Number of node features: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# Using the Cora dataset as an example\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "print(f'Number of node features: {data.num_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model <a name=\"Defining-the-Model\"></a>\n",
    "\n",
    "For this exercise, we'll use a simple Graph Convolution Network (GCN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Uncomment this line to use CUDA if available\n",
    "device = torch.device(\"mps\") # Use MPS to run on M1 Mac\n",
    "model = GCN(input_dim=data.num_features, hidden_dim=16, output_dim=dataset.num_classes).to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Training Loop <a name=\"Setting-up-the-Training-Loop\"></a>\n",
    "\n",
    "Now that we have our dataset and model, let's set up the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.9450783729553223\n",
      "Epoch: 20, Loss: 0.22880995273590088\n",
      "Epoch: 40, Loss: 0.05259493738412857\n",
      "Epoch: 60, Loss: 0.03490505367517471\n",
      "Epoch: 80, Loss: 0.030518341809511185\n",
      "Epoch: 100, Loss: 0.030535725876688957\n",
      "Epoch: 120, Loss: 0.030138257890939713\n",
      "Epoch: 140, Loss: 0.033741842955350876\n",
      "Epoch: 160, Loss: 0.02363608032464981\n",
      "Epoch: 180, Loss: 0.026172390207648277\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss for every 20 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Training Results <a name=\"Evaluating-Training-Results\"></a>\n",
    "\n",
    "After training, it's essential to understand how our model is performing.\n",
    "We'll do this by evaluating its accuracy on the validation and test datasets.\n",
    "\n",
    "First, let's define a helper function to compute accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(output, labels, mask):\n",
    "    _, predictions = output.max(dim=1)\n",
    "    correct = predictions[mask].eq(labels[mask]).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute the accuracy for our trained model on the validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7840\n",
      "Test Accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output = model(data)\n",
    "\n",
    "val_accuracy = compute_accuracy(output, data.y, data.val_mask)\n",
    "test_accuracy = compute_accuracy(output, data.y, data.test_mask)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section gives insight into the effectiveness of the trained model.\n",
    "Depending on the dataset and architecture details, you might achieve different results.\n",
    "Adjusting hyperparameters, model architecture, or training strategy can be next steps if results are unsatisfactory.\n",
    "If interested, you can also check out how to use libaries like [Optuna](https://optuna.org) and [DeepHyper](https://deephyper.readthedocs.io/en/latest/) to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
