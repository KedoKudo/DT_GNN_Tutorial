{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KedoKudo/DT_GNN_Tutorial/blob/tree/main/notebooks/02_pytorch_basics.ipynb)\n",
    "\n",
    "# PyTorch Basics\n",
    "\n",
    "PyTorch provides very good introductory tutorials on their [website](https://pytorch.org/tutorials/).\n",
    "We recommend beginners to go through the tutorials step by step.\n",
    "In this notebook, we will only provide a few key points for using PyTorch based on our experience.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. Detect GPU\n",
    "0. Numpy and PyTorch.Tensor\n",
    "0. Basic training procedure\n",
    "0. Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line to install the required packages\n",
    "# !pip install torch torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Detect GPU\n",
    "\n",
    "PyTorch can automatically detect whether a GPU is available.\n",
    "Although it is possible to use PyTorch on CPU, we strongly recommend to use GPU for training.\n",
    "\n",
    "- For x86_64, use\n",
    "\n",
    "```python\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "```\n",
    "\n",
    "- For Apple silicon, use\n",
    "\n",
    "```python\n",
    "import torch\n",
    "device = torch.device('mps')\n",
    "```\n",
    "\n",
    "If there are multiple GPUs, you can specify which GPU to use by\n",
    "\n",
    "```python\n",
    "import torch\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "```\n",
    "which will use the second GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# This block is run on MacbookPro with M1-pro chip, you need to update the device name to match your device\n",
    "import torch\n",
    "device = torch.device('mps')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now all features are supported on Apple silicon yet, so we recommend to use x86_64 for now if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numpy and PyTorch.Tensor\n",
    "\n",
    "PyTorch offers an easy way to convert between Numpy arrays and its tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert a Numpy array to a Torch tensor\n",
    "numpy_array = np.array([1, 2, 3, 4, 5])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(tensor_from_numpy)\n",
    "\n",
    "# Convert a Torch tensor to a Numpy array\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "numpy_from_tensor = tensor.numpy()\n",
    "print(numpy_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DO NOT mix use of Numpy and PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenzhang/Github/DT_GNN_Tutorial/notebooks/02_pytorch_basics.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chenzhang/Github/DT_GNN_Tutorial/notebooks/02_pytorch_basics.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m numpy_array \u001b[39m*\u001b[39;49m tensor_from_numpy\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "# Notice that an error will occur if you try to operate a numpy array and a torch tensor\n",
    "numpy_array * tensor_from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Until a tensor is explicitly sent to GPU, it is always on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_numpy.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure return the handle if you want to keep track of the data sent to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle is still pointed to the CPU one\n",
    "tensor_from_numpy.to(device)\n",
    "tensor_from_numpy.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle is now pointed to the GPU one\n",
    "tensor_from_numpy = tensor_from_numpy.to(device)\n",
    "tensor_from_numpy.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic training procedure\n",
    "\n",
    "PyTorch provides a very flexible way to train a model, and provides many useful tools to simpiify the training procedure.\n",
    "However, we still recommend beginners to follow the basic training procedure instead of using the bundled functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Loss: 0.3957580327987671\n",
      "Epoch [40/200], Loss: 0.3622252643108368\n",
      "Epoch [60/200], Loss: 0.33474501967430115\n",
      "Epoch [80/200], Loss: 0.312224805355072\n",
      "Epoch [100/200], Loss: 0.293769508600235\n",
      "Epoch [120/200], Loss: 0.27864524722099304\n",
      "Epoch [140/200], Loss: 0.2662506103515625\n",
      "Epoch [160/200], Loss: 0.2560933232307434\n",
      "Epoch [180/200], Loss: 0.24776943027973175\n",
      "Epoch [200/200], Loss: 0.24094779789447784\n",
      "Trained model: y = 2.0640x + 0.6144\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Generate synthetic data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = 2 * x + 1 + np.random.randn(100) * 0.5  # y = 2x + 1 + noise\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.FloatTensor(x).view(-1, 1)\n",
    "y_tensor = torch.FloatTensor(y).view(-1, 1)\n",
    "\n",
    "# Model Definition\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # Single input and single output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 20 epochs\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Get the learned parameters\n",
    "learned_weight = model.linear.weight.item()\n",
    "learned_bias = model.linear.bias.item()\n",
    "print(f\"Trained model: y = {learned_weight:.4f}x + {learned_bias:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code example will run on CPU by default, and you can change it to GPU by setting `device` to `cuda` or `cuda:1` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Loss: 0.3625805974006653\n",
      "Epoch [40/200], Loss: 0.34780141711235046\n",
      "Epoch [60/200], Loss: 0.3356897532939911\n",
      "Epoch [80/200], Loss: 0.32576417922973633\n",
      "Epoch [100/200], Loss: 0.31763020157814026\n",
      "Epoch [120/200], Loss: 0.3109643757343292\n",
      "Epoch [140/200], Loss: 0.3055015206336975\n",
      "Epoch [160/200], Loss: 0.301024854183197\n",
      "Epoch [180/200], Loss: 0.2973560690879822\n",
      "Epoch [200/200], Loss: 0.2943494915962219\n",
      "Trained model: y = 2.0351x + 0.7803\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = 2 * x + 1 + np.random.randn(100) * 0.5  # y = 2x + 1 + noise\n",
    "\n",
    "# Convert data to PyTorch tensors and move them to the specified device\n",
    "x_tensor = torch.FloatTensor(x).view(-1, 1).to(device)\n",
    "y_tensor = torch.FloatTensor(y).view(-1, 1).to(device)\n",
    "\n",
    "# Model Definition\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # Single input and single output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegression().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 20 epochs\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Get the learned parameters\n",
    "learned_weight = model.linear.weight.item()\n",
    "learned_bias = model.linear.bias.item()\n",
    "print(f\"Trained model: y = {learned_weight:.4f}x + {learned_bias:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save and load models\n",
    "\n",
    "Once a model is trained, we can save it to disk and load it later for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to linear_regression_weights.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model weights\n",
    "model_path = 'linear_regression_weights.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model weights saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the next time we want to use/train the model, we can load the model from disk and continue from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.1310],\n",
      "        [41.4816]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Load the model weights\n",
    "loaded_model = LinearRegression().to(device)\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Now, the model is ready to make predictions\n",
    "x_new = np.array([[10.0], [20.0]])\n",
    "x_new_tensor = torch.FloatTensor(x_new).to(device)\n",
    "y_pred = loaded_model(x_new_tensor)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
